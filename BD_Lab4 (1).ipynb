{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name : Ghotra Jaspreet Kaur\n",
        "\n",
        "ID : 202318058"
      ],
      "metadata": {
        "id": "KbG-mOLmTEZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fstpUR1GNE5K",
        "outputId": "d86ab5ef-2274-40b7-f740-7286a86380b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=1075f222af632361b2723b3e0be0ab6da12baadc3c04297adee2e7ece565a4b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "H6gs_8wEPyu4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK-1: Generate 100 random numbers in range 0 to 10 using numpy\n",
        "randint function with the seed set to 10. Create a RDD using the paral-\n",
        "lelize function using data generated in previous step. Calculate the fre-\n",
        "quency of each number (0 - 10) using appropriate function of RDD.**"
      ],
      "metadata": {
        "id": "DWdVi4WPTc7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a Spark session\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkExample\").getOrCreate()\n",
        "\n",
        "#Generating 100 random numbers in range 0 to 10 using numpy\n",
        "import numpy as np\n",
        "np.random.seed(10)\n",
        "random_numbers = np.random.randint(0, 11, 100)\n",
        "\n",
        "#Creating RDD using parallelize function\n",
        "rdd_numbers = spark.sparkContext.parallelize(random_numbers)\n",
        "\n",
        "#Calculating the frequency of each number (0 - 10)\n",
        "frequency_count = rdd_numbers.countByValue()\n",
        "\n",
        "for num, freq in sorted(frequency_count.items()):\n",
        "    print(f\"Number {num}: {freq} times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8j2UgLHOr72",
        "outputId": "049d9e9b-6aa1-4edf-8fae-ea6529131566"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number 0: 12 times\n",
            "Number 1: 11 times\n",
            "Number 2: 8 times\n",
            "Number 3: 6 times\n",
            "Number 4: 8 times\n",
            "Number 5: 5 times\n",
            "Number 6: 11 times\n",
            "Number 7: 5 times\n",
            "Number 8: 14 times\n",
            "Number 9: 12 times\n",
            "Number 10: 8 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK-2: In this task you will calculate the frequency of each word in\n",
        "text8 dataset mentioned above. Create a RDD using the text8 dataset.\n",
        "Use appropriate functions of the RDD to get the word frequencies. Filter the RDD using appropriate function to get the frequencies of words\n",
        "containing the letter ’a’.**"
      ],
      "metadata": {
        "id": "0sCDXWpXT5BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating RDD using the text8 dataset\n",
        "text_rdd = spark.sparkContext.textFile('text8')\n",
        "\n",
        "#Calculating word frequencies\n",
        "word_frequencies = text_rdd.flatMap(lambda line: line.split()).countByValue()\n",
        "\n",
        "#Filtering frequencies to get words containing the letter 'a'\n",
        "a_words_frequencies = {word: freq for word, freq in word_frequencies.items() if 'a' in word}\n",
        "\n",
        "#Showing all the observations\n",
        "#for word, freq in sorted(a_words_frequencies.items()):\n",
        "#    print(f\"Word '{word}': {freq} times\")\n",
        "\n",
        "#Showing only the first 20 observations\n",
        "for word, freq in sorted(list(a_words_frequencies.items())[:20]):\n",
        "    print(f\"Word '{word}': {freq} times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob_yCQCAOr4p",
        "outputId": "70d6d59d-f3c2-4395-a74f-0a5c96c1e30f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 'a': 16818 times\n",
            "Word 'abuse': 23 times\n",
            "Word 'act': 179 times\n",
            "Word 'against': 459 times\n",
            "Word 'also': 2340 times\n",
            "Word 'anarchism': 156 times\n",
            "Word 'and': 22553 times\n",
            "Word 'any': 614 times\n",
            "Word 'as': 7067 times\n",
            "Word 'class': 136 times\n",
            "Word 'early': 532 times\n",
            "Word 'has': 1983 times\n",
            "Word 'means': 235 times\n",
            "Word 'organization': 99 times\n",
            "Word 'originated': 26 times\n",
            "Word 'pejorative': 6 times\n",
            "Word 'radicals': 12 times\n",
            "Word 'sans': 3 times\n",
            "Word 'that': 5987 times\n",
            "Word 'way': 350 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataFrame Task: Create a Spark dataframe using the iris json data men-\n",
        "tioned above. Calculate Pearson Correlation between the columns petal-\n",
        "Length and petalWidth using the appropriate dataframe API. Show the\n",
        "columns sepalLength, sepalWidth and species for the rows of data that has\n",
        "petalLength greater than or equal to 1.4 using the appropriate dataframe\n",
        "API.**"
      ],
      "metadata": {
        "id": "FgGGHbSdUa4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df = spark.read.json(\"iris.json\")\n",
        "iris_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI-TZPQlOr1i",
        "outputId": "d4521f74-f739-4658-b888-27d13f42357f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------+----------+-----------+----------+-------+\n",
            "|_corrupt_record|petalLength|petalWidth|sepalLength|sepalWidth|species|\n",
            "+---------------+-----------+----------+-----------+----------+-------+\n",
            "|              [|       NULL|      NULL|       NULL|      NULL|   NULL|\n",
            "|           NULL|        1.4|       0.2|        5.1|       3.5| setosa|\n",
            "|           NULL|        1.4|       0.2|        4.9|       3.0| setosa|\n",
            "|           NULL|        1.3|       0.2|        4.7|       3.2| setosa|\n",
            "|           NULL|        1.5|       0.2|        4.6|       3.1| setosa|\n",
            "|           NULL|        1.4|       0.2|        5.0|       3.6| setosa|\n",
            "|           NULL|        1.7|       0.4|        5.4|       3.9| setosa|\n",
            "|           NULL|        1.4|       0.3|        4.6|       3.4| setosa|\n",
            "|           NULL|        1.5|       0.2|        5.0|       3.4| setosa|\n",
            "|           NULL|        1.4|       0.2|        4.4|       2.9| setosa|\n",
            "|           NULL|        1.5|       0.1|        4.9|       3.1| setosa|\n",
            "|           NULL|        1.5|       0.2|        5.4|       3.7| setosa|\n",
            "|           NULL|        1.6|       0.2|        4.8|       3.4| setosa|\n",
            "|           NULL|        1.4|       0.1|        4.8|       3.0| setosa|\n",
            "|           NULL|        1.1|       0.1|        4.3|       3.0| setosa|\n",
            "|           NULL|        1.2|       0.2|        5.8|       4.0| setosa|\n",
            "|           NULL|        1.5|       0.4|        5.7|       4.4| setosa|\n",
            "|           NULL|        1.3|       0.4|        5.4|       3.9| setosa|\n",
            "|           NULL|        1.4|       0.3|        5.1|       3.5| setosa|\n",
            "|           NULL|        1.7|       0.3|        5.7|       3.8| setosa|\n",
            "+---------------+-----------+----------+-----------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the _corrupt_record column\n",
        "iris_df = iris_df.select(iris_df.columns[1:])"
      ],
      "metadata": {
        "id": "gjpk6iGVOryp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_2xqu0RSNhi",
        "outputId": "745540e3-8654-4b33-aac0-9af18d50d209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-----------+----------+-------+\n",
            "|petalLength|petalWidth|sepalLength|sepalWidth|species|\n",
            "+-----------+----------+-----------+----------+-------+\n",
            "|       NULL|      NULL|       NULL|      NULL|   NULL|\n",
            "|        1.4|       0.2|        5.1|       3.5| setosa|\n",
            "|        1.4|       0.2|        4.9|       3.0| setosa|\n",
            "|        1.3|       0.2|        4.7|       3.2| setosa|\n",
            "|        1.5|       0.2|        4.6|       3.1| setosa|\n",
            "|        1.4|       0.2|        5.0|       3.6| setosa|\n",
            "|        1.7|       0.4|        5.4|       3.9| setosa|\n",
            "|        1.4|       0.3|        4.6|       3.4| setosa|\n",
            "|        1.5|       0.2|        5.0|       3.4| setosa|\n",
            "|        1.4|       0.2|        4.4|       2.9| setosa|\n",
            "|        1.5|       0.1|        4.9|       3.1| setosa|\n",
            "|        1.5|       0.2|        5.4|       3.7| setosa|\n",
            "|        1.6|       0.2|        4.8|       3.4| setosa|\n",
            "|        1.4|       0.1|        4.8|       3.0| setosa|\n",
            "|        1.1|       0.1|        4.3|       3.0| setosa|\n",
            "|        1.2|       0.2|        5.8|       4.0| setosa|\n",
            "|        1.5|       0.4|        5.7|       4.4| setosa|\n",
            "|        1.3|       0.4|        5.4|       3.9| setosa|\n",
            "|        1.4|       0.3|        5.1|       3.5| setosa|\n",
            "|        1.7|       0.3|        5.7|       3.8| setosa|\n",
            "+-----------+----------+-----------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating Pearson Correlation between petalLength and petalWidth\n",
        "correlation = iris_df.stat.corr(\"petalLength\", \"petalWidth\")\n",
        "correlation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQLaK94fSQ67",
        "outputId": "883fc675-5210-4c66-fa8a-9ebb20477b85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9626417223780231"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Showing columns for rows with petalLength greater than or equal to 1.4\n",
        "iris_df.filter((iris_df.petalLength >= 1.4)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlHXwmZcSfK3",
        "outputId": "9ca3b900-cbdb-4b0e-db0b-e9e92495f64d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-----------+----------+-------+\n",
            "|petalLength|petalWidth|sepalLength|sepalWidth|species|\n",
            "+-----------+----------+-----------+----------+-------+\n",
            "|        1.4|       0.2|        5.1|       3.5| setosa|\n",
            "|        1.4|       0.2|        4.9|       3.0| setosa|\n",
            "|        1.5|       0.2|        4.6|       3.1| setosa|\n",
            "|        1.4|       0.2|        5.0|       3.6| setosa|\n",
            "|        1.7|       0.4|        5.4|       3.9| setosa|\n",
            "|        1.4|       0.3|        4.6|       3.4| setosa|\n",
            "|        1.5|       0.2|        5.0|       3.4| setosa|\n",
            "|        1.4|       0.2|        4.4|       2.9| setosa|\n",
            "|        1.5|       0.1|        4.9|       3.1| setosa|\n",
            "|        1.5|       0.2|        5.4|       3.7| setosa|\n",
            "|        1.6|       0.2|        4.8|       3.4| setosa|\n",
            "|        1.4|       0.1|        4.8|       3.0| setosa|\n",
            "|        1.5|       0.4|        5.7|       4.4| setosa|\n",
            "|        1.4|       0.3|        5.1|       3.5| setosa|\n",
            "|        1.7|       0.3|        5.7|       3.8| setosa|\n",
            "|        1.5|       0.3|        5.1|       3.8| setosa|\n",
            "|        1.7|       0.2|        5.4|       3.4| setosa|\n",
            "|        1.5|       0.4|        5.1|       3.7| setosa|\n",
            "|        1.7|       0.5|        5.1|       3.3| setosa|\n",
            "|        1.9|       0.2|        4.8|       3.4| setosa|\n",
            "+-----------+----------+-----------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}